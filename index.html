<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Driver Fatigue Detection (TensorFlow.js)</title>
  <style>
    * { box-sizing: border-box; }
    body {
      margin: 0;
      background: linear-gradient(135deg, #1e3c72, #2a5298);
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      color: white;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 10px;
    }
    h1 {
      margin-top: 12px;
      font-weight: 900;
      font-size: 1.6rem;
    }
    #videoContainer {
      position: relative;
      width: 100%;
      max-width: 360px;
      margin: 12px 0 8px;
      border-radius: 12px;
      overflow: hidden;
      box-shadow: 0 0 20px rgba(0, 220, 255, 0.75);
    }
    video, canvas {
      width: 100%;
      display: block;
      border-radius: 12px;
    }
    #alertBox {
      margin-top: 10px;
      padding: 12px 18px;
      border-radius: 8px;
      font-weight: bold;
      text-align: center;
      display: none;
      background-color: rgba(255, 0, 0, 0.85);
    }
  </style>
</head>
<body>
  <h1>Driver Fatigue Detection</h1>
  <div id="videoContainer">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>
  <div id="alertBox">⚠️ Drowsiness Detected!</div>

  <!-- TensorFlow + FaceLandmarks -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.3/dist/face-landmarks-detection.min.js"></script>

  <script>
    const EAR_THRESHOLD = 0.25;
    const EAR_CONSEC_FRAMES = 15;
    let closedEyesFrames = 0;
    let model;
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const alertBox = document.getElementById('alertBox');

    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      return new Promise(resolve => {
        video.onloadedmetadata = () => resolve(video);
      });
    }

    function drawCircle(point) {
      ctx.beginPath();
      ctx.arc(point[0], point[1], 3, 0, 2 * Math.PI);
      ctx.fillStyle = "cyan";
      ctx.fill();
    }

    function calculateEAR(eye) {
      const dist = (p1, p2) => Math.hypot(p1[0] - p2[0], p1[1] - p2[1]);
      const A = dist(eye[1], eye[5]);
      const B = dist(eye[2], eye[4]);
      const C = dist(eye[0], eye[3]);
      return (A + B) / (2.0 * C);
    }

    function getEyeLandmarks(keypoints, left = true) {
      if (left) {
        return [keypoints[33], keypoints[160], keypoints[158], keypoints[133], keypoints[153], keypoints[144]];
      } else {
        return [keypoints[362], keypoints[385], keypoints[387], keypoints[263], keypoints[373], keypoints[380]];
      }
    }

    async function detectFrame() {
      const predictions = await model.estimateFaces({ input: video, returnTensors: false });

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (predictions.length > 0) {
        predictions.forEach(pred => {
          const keypoints = pred.scaledMesh;

          const leftEye = getEyeLandmarks(keypoints, true);
          const rightEye = getEyeLandmarks(keypoints, false);

          leftEye.forEach(drawCircle);
          rightEye.forEach(drawCircle);

          const leftEAR = calculateEAR(leftEye);
          const rightEAR = calculateEAR(rightEye);
          const avgEAR = (leftEAR + rightEAR) / 2.0;

          if (avgEAR < EAR_THRESHOLD) {
            closedEyesFrames++;
            if (closedEyesFrames >= EAR_CONSEC_FRAMES) {
              alertBox.style.display = 'block';
            }
          } else {
            closedEyesFrames = 0;
            alertBox.style.display = 'none';
          }
        });
      } else {
        alertBox.style.display = 'none';
        closedEyesFrames = 0;
      }

      requestAnimationFrame(detectFrame);
    }

    (async function () {
      await setupCamera();
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      model = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh);
      detectFrame();
    })();
  </script>
</body>
</html>
